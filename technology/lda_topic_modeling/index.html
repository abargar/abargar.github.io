<!doctype html><html lang=en-us><head><link rel=icon href=/favicon_main.svg><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=x-ua-compatible content="ie=edge"><meta property="og:url" content="https://abargar.github.io/technology/lda_topic_modeling/"><meta property="og:type" content="article"><meta property="og:title" content="LDA and Optuna"><meta property="og:description" content="What are topics, really, but the undercurrents   of conversation, hints of broader themes that   pepper throughout our speech like spices..."><meta property="og:image:width" content="375"><meta property="og:image:height" content="250"><meta property="og:image" content="https://abargar.github.io/technology/lda_topic_modeling/ratatouille_taste_hu5695f514d32b70ba17a0a89d6bab2b16_190018_600x0_resize_box_3.png"><title>Alicia Bargar - LDA and Optuna</title><link href="https://fonts.googleapis.com/css?family=Open+Sans" rel=stylesheet><link href="https://fonts.googleapis.com/css?family=Open+Sans" rel=stylesheet><link href="https://fonts.googleapis.com/css?family=Open+Sans" rel=stylesheet><link rel=stylesheet type=text/css href=/css/style.967c29c5b48237e9ee9814a29e55171e07875e3596db0deb219743f9a74917a4.css integrity="sha256-lnwpxbSCN+numBSinlUXHgeHXjWW2w3rIZdD+adJF6Q="><link rel=stylesheet type=text/css href=/css/monokai-sublime.9.15.8.min.91376415864fdd3a92be524052267afece4bdb1bb8c6c754f5e60c5ac28e93be.css integrity="sha256-kTdkFYZP3TqSvlJAUiZ6/s5L2xu4xsdU9eYMWsKOk74="><link rel=stylesheet type=text/css href=/css/all.min.2d91c07e15fc26f2697117b326256c0a2b0586dd12a15c622a53cd47a9e54a1d.css integrity="sha256-LZHAfhX8JvJpcRezJiVsCisFht0SoVxiKlPNR6nlSh0="><link rel=stylesheet type=text/css href=/css/refresh.ccfd23f8053a1571a3e474a6877f42a6a1924c6bbf1b64c7704b49a0353b4650.css integrity="sha256-zP0j+AU6FXGj5HSmh39CpqGSTGu/G2THcEtJoDU7RlA="><link rel=stylesheet type=text/css href=/css/devicon.min.149016fbf45c8bc157d6f55ce3ee875feaa3f90446bf7d151fbc16a9f21a8859.css integrity="sha256-FJAW+/Rci8FX1vVc4+6HX+qj+QRGv30VH7wWqfIaiFk="></head><body><div id=preloader><div id=status></div></div><nav class="navbar is-fresh is-transparent no-shadow" role=navigation aria-label="main navigation"><div class=container><div class=navbar-brand><a class=navbar-item><div class="menu-icon-wrapper left-menu-icon-wrapper" style=visibility:visible><svg width="1e3" height="1e3"><path class="path1" d="M3e2 4e2H7e2c2e2.0 2e2 350-1e2 450A4e2 4e2.0 012e2 2e2L8e2 8e2"/><path class="path2" d="M3e2 5e2H7e2"/><path class="path3" d="M7e2 6e2H3e2c-2e2.0-2e2-4e2 1e2-450A4e2 380 0 112e2 8e2L8e2 2e2"/></svg><button id=menu-icon-trigger class=menu-icon-trigger></button></div><div class="navbar-item left-menu-icon-wrapper">Tags</div></a><div class="navbar-item is-expanded"></div><a class="navbar-item is-hidden-desktop"><div data-target=navbar-menu class="navbar-item right-menu-icon-wrapper is-hidden-desktop">Menu</div><div data-target=navbar-menu class="menu-icon-wrapper right-menu-icon-wrapper" style=visibility:visible><svg width="1e3" height="1e3"><path class="path1" d="M3e2 4e2H7e2c2e2.0 2e2 350-1e2 450A4e2 4e2.0 012e2 2e2L8e2 8e2"/><path class="path2" d="M3e2 5e2H7e2"/><path class="path3" d="M7e2 6e2H3e2c-2e2.0-2e2-4e2 1e2-450A4e2 380 0 112e2 8e2L8e2 2e2"/></svg><button id=menu-icon-trigger class=menu-icon-trigger></button></div></a></div><div id=navbar-menu class="navbar-menu is-static"><div class=navbar-end><a href=/about/ class="navbar-item is-secondary">About Me</a><a href=/technology/ class="navbar-item is-secondary">Technology</a></div></div></div></nav><nav id=navbar-clone class="navbar is-fresh is-transparent" role=navigation aria-label="main navigation"><div class=container><div class=navbar-brand><a class=navbar-item><div class="menu-icon-wrapper left-menu-icon-wrapper" style=visibility:visible><svg width="1e3" height="1e3"><path class="path1" d="M3e2 4e2H7e2c2e2.0 2e2 350-1e2 450A4e2 4e2.0 012e2 2e2L8e2 8e2"/><path class="path2" d="M3e2 5e2H7e2"/><path class="path3" d="M7e2 6e2H3e2c-2e2.0-2e2-4e2 1e2-450A4e2 380 0 112e2 8e2L8e2 2e2"/></svg><button id=menu-icon-trigger class=menu-icon-trigger></button></div><div class="navbar-item left-menu-icon-wrapper">Tags</div></a><div class="navbar-item is-expanded"></div><a class="navbar-item is-hidden-desktop"><div data-target=cloned-navbar-menu class="navbar-item right-menu-icon-wrapper is-hidden-desktop">Menu</div><div data-target=cloned-navbar-menu class="menu-icon-wrapper right-menu-icon-wrapper" style=visibility:visible><svg width="1e3" height="1e3"><path class="path1" d="M3e2 4e2H7e2c2e2.0 2e2 350-1e2 450A4e2 4e2.0 012e2 2e2L8e2 8e2"/><path class="path2" d="M3e2 5e2H7e2"/><path class="path3" d="M7e2 6e2H3e2c-2e2.0-2e2-4e2 1e2-450A4e2 380 0 112e2 8e2L8e2 2e2"/></svg><button id=menu-icon-trigger class=menu-icon-trigger></button></div></a></div><div id=cloned-navbar-menu class="navbar-menu is-static"><div class=navbar-end><a href=/about/ class="navbar-item is-secondary">About Me</a><a href=/technology/ class="navbar-item is-secondary">Technology</a></div></div></div></nav><section class="section is-medium"><div class=container><div class=columns><div class="column is-centered-tablet-portrait"><h1 class="title is-2 section-title">LDA and Optuna</h1><h5 class="subtitle is-5 is-muted"></h5><div class=divider></div><section class="section content has-text-justified"><p>What are topics, really, but the undercurrents of conversation, hints of broader themes that pepper throughout our speech like spices wafting from a richly flavored stew&mldr;</p><p>We are going to flip the script and look at recipes through the lenses of topic modeling to see what general categories arise. In this blog, we&rsquo;ll cover the Latent Dirichlet Algorithm (LDA), hyperparameter tuning, and other technical topics.</p><p>If you just need a coding example, you can skip down to <a href=#modeling>here</a>.</p><h2 id=what-is-topic-modeling>What is Topic Modeling?</h2><p>Topic modeling is, at its simplest, the process of finding words that frequently show up together. To a person, these co-occurring words usually end up suggesting a theme. When you hear &ldquo;bark&rdquo;, &ldquo;nose&rdquo;, and &ldquo;leash&rdquo;, what comes to mind? Even without &ldquo;dog&rdquo; appearing in there, you may have recognized that it ties these words together - thus, voila, &ldquo;dog&rdquo; is your topic.</p><p><img src=https://tenor.com/view/hi-hello-dog-there-oh-gif-11420655.gif alt="A dog says hello"></p><p>One of the most common ways to do topic modeling is <strong>Latent Dirichlet Algorithm (LDA)</strong>. This is an <strong>unsupervised</strong> algorithm, meaning that it does not require ground truth information, but instead arises patterns found inherently in the data. This can be really cool to identify hidden themes among a bunch of documents, which can give you a high-level understanding without having to go through and read every article.</p><p>A cautionary note: words get used in a variety of contexts. &ldquo;Bark&rdquo; could be a dog&rsquo;s bark or the bark of a tree. Since language is tricky this way, we don&rsquo;t want to say the presence of a word definitely indicates a topic - instead, what we&rsquo;ll do is say that there&rsquo;s a certain probability of a word representing each topic; we can then roll these up to get a probability for each document/recipe as to whether it contains each topic.</p><p>In a recipe sense, think of this as onions - onions show up everywhere, so they&rsquo;re not a great indicator for, say, Italian vs. Mexican vs. Indian food. On the other hand, penne, chipotle peppers, and turmeric are more specific - they&rsquo;ll indicate a higher probability of those individual cuisines. A recipe with onions and chipotle peppers will have a very small but not-0 probability of belonging to the Italian topic (thanks to onions) and a very high probability of belonging to the Mexican topic.</p><p>I recognize this is a lot to take in. If you&rsquo;re interested and want to learn more, <a href=http://journalofdigitalhumanities.org/2-1/topic-modeling-a-basic-introduction-by-megan-r-brett/>this</a> is a good resource for explaining topic modeling and its strengths and weaknesses. <a href=https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158>This article</a> goes into additional depth on LDA so you can understand what&rsquo;s happening under the hood.</p><h2 id=hyperparameter-optimization>Hyperparameter Optimization</h2><p>Next, to get our best possible set of modelled topics, we need to do some hyperparameter tuning. A <strong>hyperparameter</strong> is a parameter, or option, that you must decide upon when training your machine learning model. Think of it this way - you train a model so it can make &lsquo;decisions&rsquo; (e.g. classifications, detections) without you. Hyperparameters help define the form of this training, and thus what kind of model you&rsquo;re going to make. If you&rsquo;re into Pokemon, a tangible comparison to this is how Eevee can evolve into a multitude of different variations based on the conditions under which you train it. Eevee&rsquo;s environmental conditions are metaphorically like hyperparameters, in that they affect its training and eventual outcomes.</p><p>LDA has three hyperparameters that we&rsquo;ll need to tune:</p><ul><li><p><strong>n_topics</strong> - the LDA algorithm requires the number of topics upfront. This can be tricky since the whole reason you&rsquo;re running LDA is to learn what topics exist.</p></li><li><p><strong>alpha</strong> - topic-document density; the larger alpha, the more topics you expect to be in a document, and vice versa.</p></li><li><p><strong>eta</strong> - topic-word density; the larger beta, the more words from your documents are part of topics , and vice versa</p></li></ul><p><a href="https://www.thoughtvector.io/blog/lda-alpha-and-beta-parameters-the-intuition/#:~:text=LDA%20Alpha%20and%20Beta%20Parameters%20-%20The%20Intuition.,via%20an%20open%20source%20implementation%20like%20Python%E2%80%99s%20gensim">This page</a> explains alpha and eta in a really nice and coherent way.</p><p>You can spend a lot of time tinkering with different values for your hyperparameters to try to find what gives you the best result. However, not today! Today we use Optuna. I&rsquo;ll show you how to do so below.</p><hr><h2 id=the-code>The Code</h2><p>For this example, I will use this open-source dataset of 250,000 recipes: <a href>https://eightportions.com/datasets/Recipes/</a>.</p><p>You will need Python and the following libraries, installable from pip or conda: <strong>gensim</strong>, <strong>optuna</strong>, <strong>pyarrow</strong>, and <strong>pandas</strong>. The full example code from file ingestion through modeling is available <a href=https://github.com/abargar/optuna_example>here</a>.</p><h3 id=featuretoken-creation>Feature/Token Creation</h3><p><a href=https://github.com/abargar/optuna_example/blob/main/process_ingredients.py>This</a> is the script where I process features from files. In general, this is what I do:</p><ol><li><p>I iterate through each file/recipe to pull out the recipe name and ingredient list (lines 38-47)</p></li><li><p>I combine the name and ingredients into a single string (lines 50-52)</p></li><li><p>I get rid of punctuation and numbers (lines 29-33)</p></li><li><p>I get rid of <a href=https://github.com/abargar/optuna_example/blob/main/useless_words.txt>useless words</a>, like &ldquo;a&rdquo;, &ldquo;into&rdquo;, &ldquo;advertisement&rdquo;, and &ldquo;fresh&rdquo; (I&rsquo;m cynical. Also, line 34)</p></li><li><p>I save the resulting tokens to a file.</p></li></ol><h3 id=modeling>Modeling</h3><p><a href=https://github.com/abargar/optuna_example/blob/main/model.py>This</a> is the script to generate the topic model.</p><p>First, we need to prepare the corpus - the list of tokens - into a format readable by the model. Because we cannot pass corpora_dict and corpus directly into optuna&rsquo;s optimize function, we define them here as global variables.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>token_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;data/tokenized_ingredients.parquet&#34;</span>)
</span></span><span style=display:flex><span>tokens_list <span style=color:#f92672>=</span> token_df<span style=color:#f92672>.</span>tokens<span style=color:#f92672>.</span>values
</span></span><span style=display:flex><span>corpora_dict <span style=color:#f92672>=</span> corpora<span style=color:#f92672>.</span>Dictionary(tokens_list)
</span></span><span style=display:flex><span>corpus <span style=color:#f92672>=</span> [corpora_dict<span style=color:#f92672>.</span>doc2bow(tokens) <span style=color:#66d9ef>for</span> tokens <span style=color:#f92672>in</span> tokens_list]
</span></span></code></pre></div><p>In order to optimize performance, we need something to optimize towards. <a href=https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_coherence_model_selection.ipynb>Coherence</a> measures well the topics are represented by their highest probability words - how frequently do these words actually appear together - and is correlated with how human-interpretable the end topics are. This function handles the coherence calculation.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>compute_coherence</span>(model, corpus, corpora_dict):
</span></span><span style=display:flex><span>    coherence_model_lda <span style=color:#f92672>=</span> CoherenceModel(
</span></span><span style=display:flex><span>        model<span style=color:#f92672>=</span>model,
</span></span><span style=display:flex><span>        texts<span style=color:#f92672>=</span>corpus,
</span></span><span style=display:flex><span>        corpus<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>,
</span></span><span style=display:flex><span>        dictionary<span style=color:#f92672>=</span>corpora_dict,
</span></span><span style=display:flex><span>        coherence<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;c_v&#34;</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> coherence_model_lda<span style=color:#f92672>.</span>get_coherence()
</span></span></code></pre></div><p>This is the crux of Optuna- defining the objective that we will be optimizing. Note that here we define uniform distributions for alpha, eta, and the number of topics (ntopics) for Optuna to sample from. Next, we define our most ideal outcome score. Maximum coherence is 1, but this can be tricky as it usually indicates an underlying problem with the data. Thus, we set our ideal score to a more realistic 0.8. The model is then created with these parameters and tested over the dataset. Post-creating the model, the coherence score is calculated and the model outputs are stored via the function <em>write_model_results</em>. The output of this function is the difference between the computed coherence score and the ideal 0.8 score.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>objective</span>(trial):
</span></span><span style=display:flex><span>    alpha <span style=color:#f92672>=</span> trial<span style=color:#f92672>.</span>suggest_uniform(<span style=color:#e6db74>&#34;alpha&#34;</span>, <span style=color:#ae81ff>0.01</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    eta <span style=color:#f92672>=</span> trial<span style=color:#f92672>.</span>suggest_uniform(<span style=color:#e6db74>&#34;eta&#34;</span>, <span style=color:#ae81ff>0.01</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    ntopics <span style=color:#f92672>=</span> trial<span style=color:#f92672>.</span>suggest_uniform(<span style=color:#e6db74>&#34;num_topics&#34;</span>, <span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>    ideal_score <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.8</span>
</span></span><span style=display:flex><span>    model <span style=color:#f92672>=</span> gensim<span style=color:#f92672>.</span>models<span style=color:#f92672>.</span>LdaMulticore(
</span></span><span style=display:flex><span>        workers<span style=color:#f92672>=</span><span style=color:#ae81ff>7</span>,
</span></span><span style=display:flex><span>        corpus<span style=color:#f92672>=</span>corpus,
</span></span><span style=display:flex><span>        id2word<span style=color:#f92672>=</span>corpora_dict,
</span></span><span style=display:flex><span>        num_topics<span style=color:#f92672>=</span>ntopics,
</span></span><span style=display:flex><span>        random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,
</span></span><span style=display:flex><span>        passes<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>,
</span></span><span style=display:flex><span>        alpha<span style=color:#f92672>=</span>alpha,
</span></span><span style=display:flex><span>        eta<span style=color:#f92672>=</span>eta,
</span></span><span style=display:flex><span>        per_word_topics<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    coherence_score <span style=color:#f92672>=</span> compute_coherence(model, tokens_list, corpora_dict)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Trial </span><span style=color:#e6db74>{</span>trial<span style=color:#f92672>.</span>number<span style=color:#e6db74>}</span><span style=color:#e6db74> coherence score: </span><span style=color:#e6db74>{</span>round(coherence_score,<span style=color:#ae81ff>3</span>)<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    write_model_results(trial, model, coherence_score)
</span></span><span style=display:flex><span>    coherence_score_diff <span style=color:#f92672>=</span> abs(ideal_score <span style=color:#f92672>-</span> coherence_score)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> coherence_score_diff
</span></span></code></pre></div><p>Lastly - outside of any function, in <em>main</em> - we create the study. Here we pass the objective function we want to optimize and how many trials we want to run for. As it runs, it will print the ongoing best trial and best trial parameters. Don&rsquo;t freak out if the score looks different in this logger, as optuna tracks the difference between calculated and ideal coherence scores.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>study <span style=color:#f92672>=</span> optuna<span style=color:#f92672>.</span>create_study()
</span></span><span style=display:flex><span>study<span style=color:#f92672>.</span>optimize(objective, n_trials<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>)
</span></span><span style=display:flex><span>Path(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;models&#34;</span>)<span style=color:#f92672>.</span>mkdir(exist_ok<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>logger<span style=color:#f92672>.</span>info(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Best trial: </span><span style=color:#e6db74>{</span>study<span style=color:#f92672>.</span>best_trial<span style=color:#f92672>.</span>number<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>logger<span style=color:#f92672>.</span>info(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Best trial info: </span><span style=color:#e6db74>{</span>study<span style=color:#f92672>.</span>best_trial<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><p>At the end, open the file &ldquo;model_results.csv&rdquo;. Your top model will be the one with the highest coherence score. All of the accompanying goodies, e.g. top words per topic, will be stored in the file location &ldquo;models/trial_{trial_number}.&rdquo;</p><hr><h2 id=the-results>The Results</h2><p>Finally we have completed the modeling process. Let&rsquo;s see what we&rsquo;ve got!</p><p><img src=https://tenor.com/view/sing-sing-universal-drum-roll-buster-moon-gif-7389474.gif alt="Drumroll please!"></p><p>My best trial was the 61st, with 10 topics, an alpha of 0.45 ( fairly average topic-document density), and an eta of 0.06 (few words co-occur frequently). My coherence was 0.59, decent given the limited amount of preprocessing.</p><h3 id=top-words>Top Words</h3><p><strong>0 -</strong> <strong>Italian or French?</strong>: chopped, oil, pepper, olive, salt, finely, leaves, black, lemon, garlic, red, parsley,&mldr;</p><p><strong>1 - Savory bread & pizza making</strong>: bread, slices, salt, egg, oil, flour, sliced, sugar, water, cheese,</p><p><strong>2 -</strong> I think this one may be <strong>Mexican</strong>: sauce, cilantro, minced, beef, large, red, chile, cloves, corn, peeled,</p><p><strong>3 -</strong> <strong>Also Italian?</strong>: chopped, ounce, pepper, garlic, salt, can, oil, taste, olive, dried, &mldr;.</p><p><strong>4 -</strong> <strong>Potato time</strong>: cheese, cream, ounce, chopped, shredded, potatoes, pepper, salt, butter, cheddar,</p><p><strong>5 -</strong> <strong>Baking</strong>: sugar, butter, flour, vanilla, salt, extract, baking, cream, allpurpose, chocolate,</p><p><strong>6 -</strong> <strong>&ldquo;Asian&rdquo;</strong>: sauce, chicken, pepper, chopped, oil, salt, garlic, rice, powder, onion, minced, black, pork, soy,</p><p><strong>7 -</strong> <strong>Cocktails</strong>: juice, ounce, orange, sugar, lemon, lime, as, water, ice, fluid, pineapple, white, frozen, garnish</p><p><strong>8 -</strong> <strong>Salads</strong>: sliced, thinly, peeled, cut, oil, salad, vinegar, white, salt, juice, chopped, apple, pepper, green,</p><p><strong>9 -</strong> <strong>???:</strong> pepper, chopped, salt, shrimp, diced, oil, black, peeled, butter, large, red, sliced,</p><p>As anticipated, some topics are more coherent, and others are made clearer with access to a larger set. <a href=https://github.com/abargar/optuna_example/blob/main/example_50topwords.txt>Here</a> is my full list with up to 50 words per topic if you&rsquo;d like to peruse.</p><h3 id=most-topical-recipes>Most Topical Recipes</h3><p>Next, I&rsquo;d like to see which recipes are most representative of these topics. This might shed some light on the topics that are harder to crack (looking at you, 1, 4, and 10).</p><p>For brevity, I&rsquo;ll just include the top 3, but the full list is <a href=https://github.com/abargar/optuna_example/blob/main/topical_recipes.txt>here</a> :</p><p><strong>0 -</strong> Marinated Lamb Shoulder Chops, Red Wine-Rosemary Grilled&mldr;</p><p><strong>1 -</strong> Scali, Eggplant Parmigiana, Fougasse, Italian Loaf, Challah</p><p><strong>2 -</strong> Dos Toros Quesidilias, Fish Tacos, Chorizo Burger</p><p><strong>3 -</strong> Chili, Chili, Stew</p><p><strong>4 -</strong> 3 Cheese Enchilada, Potato Casserole, Mac and Cheese</p><p><strong>5 -</strong> Chocolate Cake, Chocolate Chip Cookies</p><p><strong>6 -</strong> Chicken Lettuce Wraps, Chicken Chow Mein, Sweet and Spicy Pork</p><p><strong>7 -</strong> Punch, Sangria, Terrine</p><p><strong>8 -</strong> Apple and Raisin Slaw, Sush-Roll Rice Salad, Tuna Maki</p><p><strong>9 -</strong> Fettucini with Rabbit, Roasted Turkey, Spitfire Shrimp</p><hr><h3 id=take-aways>Take Aways</h3><p>From an experimental perspective - hey, that wasn&rsquo;t bad! This approach found coherent groupings that make sense on both a word-based and document/recipe-based perspective.</p><p>From a data perspective - this is a great example of how your dataset impacts what you find. My Mexican partner was deeply unimpressed by cluster number 3 and what they did to jicama in the salad section. We would certainly find different groupings had we worked with a dataset that was less focused on an English-speaking audience, or at least had broader representation.</p><p>Even if I don&rsquo;t cook from this dataset. I&rsquo;m simply satisfied we made it through a complex problem, and found something interesting at the end. That&rsquo;s a wrap, folks! Bon appetit!</p><p><img src=https://media.gifs.nl/ratatouille-gifs-eC41Kp.gif alt="Bon appetit!"></p></section></div></div></div></section><footer class="footer footer-dark"><div class=container><div class=columns><div class=column><img src=/footer.svg alt></div><div class=column><div class=footer-column><div class=footer-header><h3>Website</h3></div><ul class=link-list><li><a href=/><span class=icon><i class="fa fa-home"></i></span> Homepage</a></li><li><a href=/credits/><span class=icon><i class="fa fa-cube"></i></span>
Credits</a></li><li><a href=/tags/><span class=icon><i class="fa fa-tag"></i></span>
All Tags</a></li></ul></div></div><div class=column><div class=footer-column><div class=footer-header><h3>Contacts</h3></div><ul class=link-list><li><a href=https://www.linkedin.com/aliciabargar target=_blank><span class=icon><i class="fab fa-linkedin"></i></span>
LinkedIn</a></li><li><a href=https://github.com/abargar target=_blank><span class=icon><i class="fab fa-github-square"></i></span>
Github</a></li></ul></div></div><div class=column><div class=footer-column><div class=footer-header><h3>Copyright</h3></div><ul class=link-list><li><a><span class=icon><i class="fa fa-copyright"></i></span>
Alicia Bargar - 2021</a></li></ul></div></div></div></div></footer><div id=backtotop><a href=#></a></div><div class="sidebar scroll"><div class=sidebar-header><img src=/sidebar.svg alt>
<a class=sidebar-close href=javascript:void(0);><i data-feather=x></i></a></div><div class=inner><ul class=sidebar-menu><li class=no-children><a href=/tags/><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cubes"></i></span>
All Tags</td><td class=has-text-right></td></tr></table></div></a><li class=no-children><a href=/tags/technology><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>technology</td><td class=has-text-right><div class=tag-number>3</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/disinformation><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>disinformation</td><td class=has-text-right><div class=tag-number>2</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/misinformation><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>misinformation</td><td class=has-text-right><div class=tag-number>2</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/nlp><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>nlp</td><td class=has-text-right><div class=tag-number>2</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/research><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>research</td><td class=has-text-right><div class=tag-number>2</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/social-network-analysis><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>social network analysis</td><td class=has-text-right><div class=tag-number>2</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/advanced><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>advanced</td><td class=has-text-right><div class=tag-number>1</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/beginner><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>beginner</td><td class=has-text-right><div class=tag-number>1</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/hyperparameter><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>hyperparameter</td><td class=has-text-right><div class=tag-number>1</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/information-operations><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>information operations</td><td class=has-text-right><div class=tag-number>1</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/intermediate><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>intermediate</td><td class=has-text-right><div class=tag-number>1</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/lda><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>lda</td><td class=has-text-right><div class=tag-number>1</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/natural-language-processing><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>natural language processing</td><td class=has-text-right><div class=tag-number>1</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/optuna><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>optuna</td><td class=has-text-right><div class=tag-number>1</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/propaganda><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>propaganda</td><td class=has-text-right><div class=tag-number>1</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/topic-modeling><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>topic modeling</td><td class=has-text-right><div class=tag-number>1</div></td></tr></table></div></a></li><li class=no-children><a href=/tags/tutorial><div class=columns><table width=100%><tr><td><span class=icon><i class="fa fa-cube"></i></span>tutorial</td><td class=has-text-right><div class=tag-number>1</div></td></tr></table></div></a></li></ul></div></div><script src=/js/jquery-2.2.4.893e90f6230962e42231635df650f20544ad22affc3ee396df768eaa6bc5a6a2.js integrity="sha256-iT6Q9iMJYuQiMWNd9lDyBUStIq/8PuOW33aOqmvFpqI="></script>
<script src=/js/feather.4.22.0.1ab07abeb9975f283f6b5f29451981be680fbf77ea778f991d457511d210476a.js integrity="sha256-GrB6vrmXXyg/a18pRRmBvmgPv3fqd4+ZHUV1EdIQR2o="></script>
<script src=/js/modernizr-3.6.0.e013a1e54e3c19d83537ba42b900d34451e5e4b2e789be27a02ac9b152edb741.js integrity="sha256-4BOh5U48Gdg1N7pCuQDTRFHl5LLnib4noCrJsVLtt0E="></script>
<script src=/js/refresh.62c1a9b7d85bcf4d944cd585a01dfa8fb15112a7d2cf9fb819db20493bfe7484.js integrity="sha256-YsGpt9hbz02UTNWFoB36j7FREqfSz5+4GdsgSTv+dIQ="></script><script>window.MathJax={loader:{load:["core","input/tex-base","output/chtml"],source:{core:"/js/mathjax/core.d48fedf25c74c54fa6bf79646de92b02155872bdc4f5f7d0bbfc662523d8b4f5.js","input/tex-base":"/js/mathjax/tex-base.1b68b8741dfc54e8f7222f88bea8ffcfc57ac54b2a2d8f4edf6800aa44d49441.js","output/chtml":"/js/mathjax/chtml.926cd166e0f8c1f8a566a718d60c9c58a2b7142b156d30d5f02cec7c3b0ad60a.js","output/chtml/fonts/tex":"/js/mathjax/tex_out.b8b2bb939c0dae84bf1390bfe6d32af13e83f647cdac01d544d2a7a517477e9d.js"}},chtml:{fontURL:"/fonts"}}</script><script src=/js/mathjax/startup.234a2513e6bdbc1eee06ca19abceca30fe4034e82afb373c08274c1ba2feb1a6.js integrity="sha256-I0olE+a9vB7uBsoZq87KMP5ANOgq+zc8CCdMG6L+saY="></script>
<script src=/js/highlight.9.18.1.b1c58829c55afcc1f568022af4b08ed8976da404d2990b7535bd8e19c0e3310c.js integrity="sha256-scWIKcVa/MH1aAIq9LCO2JdtpATSmQt1Nb2OGcDjMQw="></script>
<script src=/js/highlightjs-line-numbers.2.7.0.min.ddfe282e07b7ec1ed069c23f92c7c8216ddb3f1879c4e962d37fd52adbd15a05.js integrity="sha256-3f4oLge37B7QacI/ksfIIW3bPxh5xOli03/VKtvRWgU="></script><script>hljs.initHighlightingOnLoad(),hljs.initLineNumbersOnLoad(),document.addEventListener("DOMContentLoaded",e=>{document.querySelectorAll(".codeinline").forEach(e=>{hljs.highlightBlock(e)})})</script></body></html>